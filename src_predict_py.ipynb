{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.data_loader import get_data\n",
        "from src.model import DyanFHEGPIAN\n",
        "from src.train import create_sequences, SEQ_LEN, TARGET_COL, DEVICE\n",
        "from src.utils import plot_predictions, calculate_metrics, create_results_dir\n",
        "\n",
        "def predict_future(model, data_scaled, num_days, seq_len, scaler_target):\n",
        "    \"\"\"\n",
        "    Generates future predictions by iteratively feeding the last prediction back into the model.\n",
        "    \"\"\"\n",
        "    # Get the last known sequence from the data\n",
        "    last_sequence = data_scaled[-seq_len:]\n",
        "    future_predictions = []\n",
        "\n",
        "    current_sequence = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    print(f\"Generating predictions for the next {num_days} days...\")\n",
        "    for _ in range(num_days):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Get the prediction (scaled value)\n",
        "            next_pred_scaled = model(current_sequence)[0]\n",
        "\n",
        "            # Inverse transform to see the actual value (for inspection)\n",
        "            # next_pred_actual = scaler_target.inverse_transform(next_pred_scaled.cpu().numpy())\n",
        "            # print(f\"Predicted Day {_+1}: {next_pred_actual[0][0]:.2f}\")\n",
        "\n",
        "            # Append the scaled prediction to our list\n",
        "            future_predictions.append(next_pred_scaled.cpu().numpy()[0, 0])\n",
        "\n",
        "            # Create the new input for the next prediction\n",
        "            # The new input is the last `seq_len-1` observations plus the new prediction\n",
        "            # We need to create a full feature vector for the new time step.\n",
        "            # This is a simplification: we'll use the predicted 'Close' and carry over other features.\n",
        "            new_row = current_sequence.cpu().numpy()[0, -1, :].copy()\n",
        "            new_row[-1] = next_pred_scaled.cpu().numpy()[0, 0] # Update the target column\n",
        "\n",
        "            new_sequence_np = np.vstack([current_sequence.cpu().numpy()[0, 1:, :], new_row])\n",
        "            current_sequence = torch.tensor(new_sequence_np, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    return np.array(future_predictions)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to load model and make predictions.\"\"\"\n",
        "    create_results_dir()\n",
        "\n",
        "    # --- 1. Load and Prepare Data ---\n",
        "    df = get_data(ticker=\"MSFT\")\n",
        "\n",
        "    # We need the full dataset to create the last sequence for future prediction\n",
        "    features = df.drop(columns=[TARGET_COL])\n",
        "    target = df[[TARGET_COL]]\n",
        "\n",
        "    scaler_features = MinMaxScaler()\n",
        "    scaler_target = MinMaxScaler()\n",
        "\n",
        "    features_scaled = scaler_features.fit_transform(features)\n",
        "    target_scaled = scaler_target.fit_transform(target)\n",
        "\n",
        "    data_scaled = np.concatenate([features_scaled, target_scaled], axis=1)\n",
        "\n",
        "    # --- 2. Load the Trained Model ---\n",
        "    # We need to know the best hyperparameters to instantiate the model architecture\n",
        "    # For this script, we'll use some default good parameters.\n",
        "    # In a real pipeline, you would save/load these from the training run.\n",
        "    best_params = {\n",
        "        'lr': 0.001, 'embed_dim': 64, 'hidden_dim': 128,\n",
        "        'num_heads': 4, 'lambda_physics': 0.1\n",
        "    }\n",
        "\n",
        "    input_dim = data_scaled.shape[1]\n",
        "    maxvit_params = {'embed_dim': best_params['embed_dim'], 'num_heads': best_params['num_heads'], 'num_blocks': 2}\n",
        "    feinn_params = {'hidden_dim': best_params['hidden_dim'], 'output_dim': 1, 'n_layers': 2}\n",
        "    dhgann_params = {'hidden_dim': best_params['hidden_dim'], 'output_dim': best_params['hidden_dim'] // 2, 'num_heads': best_params['num_heads']}\n",
        "\n",
        "    model = DyanFHEGPIAN(\n",
        "        input_dim=input_dim,\n",
        "        seq_len=SEQ_LEN,\n",
        "        maxvit_params=maxvit_params,\n",
        "        feinn_params=feinn_params,\n",
        "        dhgann_params=dhgann_params\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load('dyan_fheg_pian_model.pth', map_location=DEVICE))\n",
        "        print(\"Trained model loaded successfully.\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: Trained model 'dyan_fheg_pian_model.pth' not found.\")\n",
        "        print(\"Please run 'python src/train.py' first.\")\n",
        "        return\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # --- 3. Predict on Test Set & Future ---\n",
        "    # Predict on the test set (last 20% of data)\n",
        "    _, X_test = create_sequences(data_scaled, SEQ_LEN)\n",
        "    test_len = int(len(X_test) * 0.2)\n",
        "    X_test_subset = torch.tensor(X_test[-test_len:], dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_preds_scaled = model(X_test_subset)[0]\n",
        "\n",
        "    test_preds = scaler_target.inverse_transform(test_preds_scaled.cpu().numpy())\n",
        "    actuals = df[TARGET_COL].values[-len(test_preds):]\n",
        "\n",
        "    # Generate future predictions\n",
        "    # Predict for roughly one year (252 trading days)\n",
        "    future_preds_scaled = predict_future(model, data_scaled, num_days=252, seq_len=SEQ_LEN, scaler_target=scaler_target)\n",
        "    future_preds = scaler_target.inverse_transform(future_preds_scaled.reshape(-1, 1))\n",
        "\n",
        "    # --- 4. Visualize Results ---\n",
        "    # Combine actuals, test predictions, and future predictions for plotting\n",
        "\n",
        "    # Dates for plotting\n",
        "    test_dates = df.index[-len(test_preds):]\n",
        "    last_date = df.index[-1]\n",
        "    future_dates = pd.to_datetime(pd.date_range(start=last_date + pd.Timedelta(days=1), periods=len(future_preds)))\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(18, 8))\n",
        "    plt.plot(df.index, df[TARGET_COL], label='Historical Actual Price', color='black')\n",
        "    plt.plot(test_dates, test_preds, label='Model Forecast on Test Data', color='orange', linestyle='--')\n",
        "    plt.plot(future_dates, future_preds, label='Future Forecast (2025)', color='red', linestyle='--')\n",
        "\n",
        "    plt.title(f'MSFT Stock Price Forecast using Dyan-FHEG-PIAN')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Stock Price (USD)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('results/full_forecast.png')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n--- Test Set Performance ---\")\n",
        "    calculate_metrics(actuals, test_preds)\n",
        "    print(\"Prediction plot saved to results/full_forecast.png\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "7x1W8P_064i5"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
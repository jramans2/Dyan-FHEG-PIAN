{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple MobileNet-style inverted residual block (MBConv).\n",
        "    This is used within the MaxViT blocks.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, stride=1, expand_ratio=4):\n",
        "        super(MBConv, self).__init__()\n",
        "        self.stride = stride\n",
        "        hidden_dim = in_channels * expand_ratio\n",
        "\n",
        "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
        "\n",
        "        layers = []\n",
        "        # Expansion phase\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(nn.Conv1d(in_channels, hidden_dim, kernel_size=1, bias=False))\n",
        "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "            layers.append(nn.GELU())\n",
        "\n",
        "        # Depthwise convolution\n",
        "        layers.append(nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False))\n",
        "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "        layers.append(nn.GELU())\n",
        "\n",
        "        # Projection phase\n",
        "        layers.append(nn.Conv1d(hidden_dim, out_channels, kernel_size=1, bias=False))\n",
        "        layers.append(nn.BatchNorm1d(out_channels))\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class MaxViTBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified MaxViT block for 1D time-series data.\n",
        "    It alternates between local (block) and global (grid) attention.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, num_heads, block_size=16, grid_size=8):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.block_size = block_size\n",
        "        self.grid_size = grid_size\n",
        "\n",
        "        self.mb_conv = MBConv(dim, dim)\n",
        "\n",
        "        # Local Attention\n",
        "        self.local_attention = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
        "\n",
        "        # Global Attention\n",
        "        self.global_attention = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is expected to be (batch, sequence_length, features)\n",
        "        B, L, C = x.shape\n",
        "\n",
        "        # MBConv part\n",
        "        x_conv = x.permute(0, 2, 1) # (B, C, L)\n",
        "        x_conv = self.mb_conv(x_conv)\n",
        "        x_conv = x_conv.permute(0, 2, 1) # (B, L, C)\n",
        "        x = x + x_conv\n",
        "\n",
        "        # --- Local Attention ---\n",
        "        # Pad sequence to be divisible by block_size\n",
        "        pad_len = (self.block_size - L % self.block_size) % self.block_size\n",
        "        x_padded = F.pad(x, (0, 0, 0, pad_len))\n",
        "\n",
        "        # Reshape for block-wise attention\n",
        "        num_blocks = x_padded.shape[1] // self.block_size\n",
        "        x_blocks = x_padded.reshape(B * num_blocks, self.block_size, C)\n",
        "\n",
        "        # Apply local attention\n",
        "        local_attn_out, _ = self.local_attention(x_blocks, x_blocks, x_blocks)\n",
        "        local_attn_out = local_attn_out.reshape(B, num_blocks * self.block_size, C)\n",
        "\n",
        "        # Remove padding\n",
        "        x_local = local_attn_out[:, :L, :]\n",
        "        x = self.norm1(x + x_local)\n",
        "\n",
        "        # --- Global Attention ---\n",
        "        # Downsample for grid attention (sparse attention)\n",
        "        x_grid = F.adaptive_avg_pool1d(x.permute(0, 2, 1), self.grid_size).permute(0, 2, 1)\n",
        "\n",
        "        # Apply global attention\n",
        "        global_attn_out, _ = self.global_attention(x_grid, x_grid, x_grid)\n",
        "\n",
        "        # Upsample back to original length\n",
        "        global_attn_out = F.interpolate(global_attn_out.permute(0, 2, 1), size=L, mode='linear').permute(0, 2, 1)\n",
        "\n",
        "        x = self.norm2(x + global_attn_out)\n",
        "\n",
        "        return x\n",
        "\n",
        "class MaxViTFeatureExtractor(nn.Module):\n",
        "    \"\"\"\n",
        "    The main MaxViT-inspired feature extractor for time-series.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, embed_dim, num_heads, num_blocks, sequence_length):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, sequence_length, embed_dim))\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            MaxViTBlock(dim=embed_dim, num_heads=num_heads) for _ in range(num_blocks)\n",
        "        ])\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.output_layer = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, sequence_length, input_dim)\n",
        "        x = self.embedding(x)\n",
        "        x = x + self.pos_embedding\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Global average pooling\n",
        "        x = x.permute(0, 2, 1) # (batch, embed_dim, seq_len)\n",
        "        x = self.pool(x).squeeze(-1) # (batch, embed_dim)\n",
        "\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage\n",
        "    BATCH_SIZE = 4\n",
        "    SEQ_LEN = 60 # e.g., 60 days of data\n",
        "    INPUT_DIM = 10 # Number of features (Open, High, Low, Close, Volume, etc.)\n",
        "    EMBED_DIM = 64\n",
        "    NUM_HEADS = 4\n",
        "    NUM_BLOCKS = 2\n",
        "\n",
        "    model = MaxViTFeatureExtractor(\n",
        "        input_dim=INPUT_DIM,\n",
        "        embed_dim=EMBED_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        num_blocks=NUM_BLOCKS,\n",
        "        sequence_length=SEQ_LEN\n",
        "    )\n",
        "\n",
        "    # Create a dummy input tensor\n",
        "    dummy_input = torch.randn(BATCH_SIZE, SEQ_LEN, INPUT_DIM)\n",
        "\n",
        "    # Get the output features\n",
        "    output_features = model(dummy_input)\n",
        "\n",
        "    print(\"--- MaxViT Feature Extractor ---\")\n",
        "    print(f\"Input shape: {dummy_input.shape}\")\n",
        "    print(f\"Output features shape: {output_features.shape}\") # Should be (BATCH_SIZE, EMBED_DIM)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MaxViT Feature Extractor ---\n",
            "Input shape: torch.Size([4, 60, 10])\n",
            "Output features shape: torch.Size([4, 64])\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CSNLxIo3tnb",
        "outputId": "f5077ef2-1aa3-41f7-d9c6-b264bb160d15"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
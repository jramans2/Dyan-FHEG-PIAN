{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from src.feature_extraction import MaxViTFeatureExtractor\n",
        "from src.feinn import FEINN\n",
        "from src.dhgann import DHGANN\n",
        "\n",
        "class DyanFHEGPIAN(nn.Module):\n",
        "    \"\"\"\n",
        "    The complete Dyan-FHEG-PIAN model.\n",
        "    This class integrates the MaxViT feature extractor, the FEINN, and the DHGANN\n",
        "    into a single end-to-end framework for stock forecasting.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, seq_len, maxvit_params, feinn_params, dhgann_params):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim (int): The number of raw input features (e.g., Open, High, etc.).\n",
        "            seq_len (int): The length of the input time-series sequence.\n",
        "            maxvit_params (dict): Parameters for the MaxViTFeatureExtractor.\n",
        "            feinn_params (dict): Parameters for the FEINN module.\n",
        "            dhgann_params (dict): Parameters for the DHGANN module.\n",
        "        \"\"\"\n",
        "        super(DyanFHEGPIAN, self).__init__()\n",
        "\n",
        "        # 1. Feature Extraction Module\n",
        "        self.maxvit = MaxViTFeatureExtractor(\n",
        "            input_dim=input_dim,\n",
        "            sequence_length=seq_len,\n",
        "            **maxvit_params\n",
        "        )\n",
        "        # The output dimension from MaxViT will be its embedding dimension.\n",
        "        feature_extractor_out_dim = maxvit_params['embed_dim']\n",
        "\n",
        "        # 2. FEINN Module\n",
        "        # It takes the features from MaxViT as input.\n",
        "        self.feinn = FEINN(\n",
        "            input_dim=feature_extractor_out_dim,\n",
        "            **feinn_params\n",
        "        )\n",
        "\n",
        "        # 3. DHGANN Module\n",
        "        # It takes the original time-series as input to build the graph.\n",
        "        self.dhgann = DHGANN(\n",
        "            input_dim=seq_len,\n",
        "            **dhgann_params\n",
        "        )\n",
        "\n",
        "        # 4. Fusion Layer\n",
        "        # This layer combines the outputs from FEINN and DHGANN.\n",
        "        # FEINN output is (batch, 1) - the predicted displacement\n",
        "        # DHGANN output is (batch, dhgann_output_dim) - the graph embedding\n",
        "        # We concatenate the DHGANN output with the MaxViT features before the final prediction.\n",
        "\n",
        "        # The final prediction will come from FEINN, but we can have an auxiliary output\n",
        "        # from DHGANN or combine them. The paper implies a synergistic model.\n",
        "        # Let's combine the feature vectors before the final prediction layers.\n",
        "\n",
        "        combined_dim = feature_extractor_out_dim + dhgann_params['output_dim']\n",
        "\n",
        "        self.fusion_layer = nn.Sequential(\n",
        "            nn.Linear(combined_dim, combined_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(combined_dim // 2, 1) # Final output is a single value (price change)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_seq):\n",
        "        \"\"\"\n",
        "        The main forward pass for the integrated model.\n",
        "\n",
        "        Args:\n",
        "            x_seq (torch.Tensor): Input time-series data of shape (batch_size, seq_len, input_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The final predicted price change.\n",
        "            torch.Tensor: The raw features passed to the physics loss function.\n",
        "        \"\"\"\n",
        "        # 1. Extract high-level temporal features with MaxViT\n",
        "        # Shape: (batch_size, maxvit_embed_dim)\n",
        "        maxvit_features = self.maxvit(x_seq)\n",
        "\n",
        "        # 2. Learn relational features with DHGANN from the raw sequence\n",
        "        # Shape: (batch_size, dhgann_output_dim)\n",
        "        dhgann_features = self.dhgann(x_seq)\n",
        "\n",
        "        # 3. Combine features from both streams\n",
        "        combined_features = torch.cat([maxvit_features, dhgann_features], dim=1)\n",
        "\n",
        "        # 4. Make the final prediction using the fusion layer\n",
        "        final_prediction = self.fusion_layer(combined_features)\n",
        "\n",
        "        # The FEINN module is used primarily for its physics-informed loss,\n",
        "        # which acts as a regularizer on the feature representation.\n",
        "        # We can pass the MaxViT features to it to compute this loss during training.\n",
        "        # We'll call this explicitly in the training loop.\n",
        "\n",
        "        return final_prediction, maxvit_features\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Example usage of the full model\n",
        "    BATCH_SIZE = 4\n",
        "    SEQ_LEN = 60\n",
        "    INPUT_DIM = 10\n",
        "\n",
        "    # Define hyperparameters for each module\n",
        "    maxvit_params = {'embed_dim': 64, 'num_heads': 4, 'num_blocks': 2}\n",
        "    feinn_params = {'hidden_dim': 128, 'output_dim': 1, 'n_layers': 2}\n",
        "    dhgann_params = {'hidden_dim': 64, 'output_dim': 32, 'num_heads': 2}\n",
        "\n",
        "    # Instantiate the full model\n",
        "    model = DyanFHEGPIAN(\n",
        "        input_dim=INPUT_DIM,\n",
        "        seq_len=SEQ_LEN,\n",
        "        maxvit_params=maxvit_params,\n",
        "        feinn_params=feinn_params,\n",
        "        dhgann_params=dhgann_params\n",
        "    )\n",
        "\n",
        "    # Create a dummy input tensor\n",
        "    dummy_input = torch.randn(BATCH_SIZE, SEQ_LEN, INPUT_DIM)\n",
        "\n",
        "    # Get the model output\n",
        "    prediction, features_for_loss = model(dummy_input)\n",
        "\n",
        "    # --- Example of Loss Calculation in a Training Loop ---\n",
        "\n",
        "    # The FEINN module is part of the main model\n",
        "    feinn_module = model.feinn\n",
        "\n",
        "    # Calculate the physics loss using the FEINN module\n",
        "    # The FEINN module itself predicts a displacement from the features\n",
        "    feinn_displacement = feinn_module(features_for_loss)\n",
        "    physics_loss = feinn_module.compute_physics_loss(features_for_loss, feinn_displacement)\n",
        "\n",
        "    print(\"--- Dyan-FHEG-PIAN Integrated Model ---\")\n",
        "    print(f\"Input shape: {dummy_input.shape}\")\n",
        "    print(f\"Final prediction shape: {prediction.shape}\")\n",
        "    print(f\"Features for physics loss shape: {features_for_loss.shape}\")\n",
        "    print(f\"Calculated Physics Loss: {physics_loss.item():.4f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pQWTEIsl6lx2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}